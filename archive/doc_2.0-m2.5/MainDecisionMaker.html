<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.4"/>
<title>Jagger: Making decision</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="my_customdoxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Jagger
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<link href="tab-panel.css" rel="stylesheet" type="text/css">
  <script language="type="text/javascript"JavaScript" type="text/javascript" src="tab-panel.js">
  </script></head>
</head>
<body onload="bodyOnLoad()" onresize="raisePanel(currentMenuIndex)">
<!-- Generated by Doxygen 1.8.4 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Packages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('MainDecisionMaker.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Groups</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Making decision </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Section describes approach how to automatically make decision about results of the performance test <br/>
</p>
<h1><a class="anchor" id="section_dm_general"></a>
General info</h1>
<p>Decision maker is required to provide result of the performance test execution. It decides if measured parameters meet acceptance criteria or not. Result provided by decision maker can be used by CI tool to rise alert when measured results don't meet expectations. <br/>
</p>
<h1><a class="anchor" id="section_dm_intro"></a>
Scope</h1>
<p>This section describes how to compare collected metrics with predefined reference values or baseline session values and decide whether performance of your system meet acceptance criteria or not. As result of comparison you can make decision and mark this test session with status flag (OK, WARNING, FATAL, ERROR). Session status will be visible to Jagger Jenkins plugin. In WebUI and PDF report summary values will be highlighted according to results of the comparison <br/>
 </p>
<div class="image">
<img src="webUI_metrics_highlighting.png" alt="webUI_metrics_highlighting.png"/>
<div class="caption">
Example of result highlighting in WebUI after comparison with limits</div></div>
<p><br/>
</p>
<h1><a class="anchor" id="section_dm_overview"></a>
Overview</h1>
<p><br/>
 Steps to go: <br/>
 </p>
<ul>
<li><a class="el" href="MainDecisionMaker.html#section_dm_describe_limits">Describe limits for measured parameters</a> </li>
<li><a class="el" href="MainDecisionMaker.html#section_dm_display">View results in WebUI and PDF report</a> </li>
<li><a class="el" href="MainDecisionMaker.html#section_dm_setup_properties">Configure baseline and auxiliary parameters</a></li>
</ul>
<p>Code presented in detailed description below is available in Jagger <a class="el" href="Installation.html#section_installation_local">archetype</a> <br/>
 <br/>
</p>
<h1><a class="anchor" id="section_dm_describe_limits"></a>
Describe limits for measured parameters</h1>
<dl class="section user"><dt>What metrics can be compared to limits</dt><dd>You can apply limits to all <a class="el" href="MetricsMain.html">collected metrics</a> <ul>
<li>performance metrics (throughput, latency, percentiles) </li>
<li>monitoring metrics (resource utilization measured by Jagger agents) </li>
<li>custom metrics </li>
<li>validators</li>
</ul>
Summary values of these metrics will be compared to limits. <br/>
 <br/>
 </dd></dl>
<dl class="section user"><dt>How to describe limits</dt><dd>You can compare you measured value either with the reference value or the measured value from the baseline session. <br/>
 <br/>
 <b> IMPORTANT </b> In all examples below, limits are relative values. Reference values or the value from baseline session is taken as a reference, thresholds to rise error and warning flags are calculated as: <b> RefValue * Limit </b> <br/>
 <br/>
 Example of the limits description: <br/>
  <div class="fragment"><div class="line">        <span class="comment">// begin: following section is used for docu generation - example of the limits</span></div>
<div class="line"></div>
<div class="line">        <span class="comment">// For standard metrics use JMetricName.</span></div>
<div class="line">        <span class="comment">// JLimitVsRefValue is used to compare the results with the referenced value.</span></div>
<div class="line">        <span class="comment">// Thresholds are relative values. In the example below, accepted range for the Success rate metric is:</span></div>
<div class="line">        <span class="comment">// 0.99 * 1.0 &lt;= Accepted values &lt;= 1.0 * 1.01</span></div>
<div class="line">        JLimit successRateLimit = JLimitVsRefValue.builder(JMetricName.PERF_SUCCESS_RATE_OK, RefValue.of(1D))</div>
<div class="line">                                                  .withOnlyWarnings(LowWarnThresh.of(0.99), UpWarnThresh.of(1.01))</div>
<div class="line">                                                  .build();</div>
<div class="line"></div>
<div class="line">        <span class="comment">// For standard metrics use JMetricName.</span></div>
<div class="line">        <span class="comment">// JLimitVsBaseline is used to compare the results with the baseline.</span></div>
<div class="line">        <span class="comment">// Use &#39;chassis.engine.e1.reporting.session.comparison.baseline.session.id&#39; to set baseline.</span></div>
<div class="line">        <span class="comment">// Thresholds are relative values. In the example below, accepted range for the Throughput metric is:</span></div>
<div class="line">        <span class="comment">// 0.99 * Reference value from the baseline session &lt;= Accepted values &lt;= Ref value * 1.00001</span></div>
<div class="line">        JLimit throughputLimit = JLimitVsBaseline.builder(JMetricName.PERF_THROUGHPUT)</div>
<div class="line">                                                 .withOnlyErrors(LowErrThresh.of(0.99), UpErrThresh.of(1.00001))</div>
<div class="line">                                                 .build();</div>
<div class="line"></div>
<div class="line">        JLoadTest jLoadTest = JLoadTest</div>
<div class="line">                .builder(Id.of(<span class="stringliteral">&quot;exampleJaggerLoadTest&quot;</span>), jTestDefinition, jLoadProfileRps, jTerminationCriteria)</div>
<div class="line">                .addListener(<span class="keyword">new</span> CollectThreadsTestListener())</div>
<div class="line">                .withLimits(successRateLimit, throughputLimit)</div>
<div class="line">                .build();</div>
<div class="line"></div>
<div class="line">        <span class="comment">// end: following section is used for docu generation - example of the limits</span></div>
</div><!-- fragment --> <br/>
 </dd></dl>
<dl class="section user"><dt>How limits and measured values are matched</dt><dd>They are matched by the metricName <br/>
 How limits will match to metrics: <br/>
 <ul>
<li>First exact match will be checked. Metric id from will be compared to the metricName attribute of the limit <br/>
 </li>
<li>If first will not match, metric id will be compared to regular expression <b>"^metricName.*"</b> <br/>
</li>
</ul>
This means limit with <em>metricName</em> 'mon_cpula_' will match metrics with ids: <br/>
 <em> mon_cpula_1|jagger_connect_57 [127.0.1.1]|-avg </em> <br/>
 <em> mon_cpula_5|jagger_connect_57 [127.0.1.1]|-avg </em> <br/>
 <em> mon_cpula_15|jagger_connect_57 [127.0.1.1]|-avg </em> <br/>
 <br/>
 If you have metrics with multiple aggregators, like in the <a class="el" href="MetricsAggregation.html">example</a>, you can assign limit to every combination of the metric-aggregator. In this case metricName for limits setup will be concatenation of the metric id and the aggregator name separated by the dash like: <em> metricId-aggregatorName </em> <br/>
 <br/>
</dd></dl>
<dl class="section user"><dt>How to enable summary calculation for monitoring metrics</dt><dd><b>NOTE:</b> Pay attention that summary is not calculated for monitoring parameters by default. You need to enable this calculation <br/>
 in property file. Like on example below: <br/>
  <div class="fragment"><div class="line"><span class="preprocessor"># begin: following section is used for docu generation - How to enable summary calculation for monitoring metrics</span></div>
<div class="line"><span class="preprocessor"></span></div>
<div class="line"><span class="preprocessor"># Uncomment following lines to enable summary value calculation for some of monitoring metrics</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#chassis.monitoring.mon_cpula_1.showSummary=true</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#chassis.monitoring.mon_cpula_5.showSummary=true</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#chassis.monitoring.mon_cpula_15.showSummary=true</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#chassis.monitoring.mon_cpu_user.showSummary=true</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#chassis.monitoring.mon_gc_minor_unit.showSummary=true</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#chassis.monitoring.mon_gc_minor_time.showSummary=true</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#chassis.monitoring.mon_gc_major_unit.showSummary=true</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#chassis.monitoring.mon_gc_major_time.showSummary=true</span></div>
<div class="line"><span class="preprocessor"></span></div>
<div class="line"><span class="preprocessor"># end: following section is used for docu generation - How to enable summary calculation for monitoring metrics</span></div>
</div><!-- fragment --></dd></dl>
<dl class="section user"><dt>How limits based decision is made</dt><dd><ol type="1">
<li>Metrics for one test are compared with limits =&gt; decision per metric <br/>
</li>
<li>Decision per test = worst decision for metrics belonging to this test <br/>
</li>
<li>Decision per test group = worst decision for tests belonging to this test <br/>
</li>
<li>Decision per session = worst decision for tests groups belonging to this test <br/>
 <br/>
 <b>NOTE:</b> Step #3 by default is executed by BasicTGDecisionMakerListener class. You can override it with your own <a class="el" href="interfacecom_1_1griddynamics_1_1jagger_1_1engine_1_1e1_1_1collector_1_1testgroup_1_1TestGroupDecisionMakerListener.html">TestGroupDecisionMakerListener</a> <br/>
 How to implement custom listeners you can read here: <a class="el" href="ListenersMain.html">User actions during the load test</a> <br/>
 <br/>
</li>
</ol>
</dd></dl>
<h1><a class="anchor" id="section_dm_display"></a>
View results in WebUI and PDF report</h1>
<p>Summary value for metrics compared to limits will be highlighted in PDF report and WebUi according to result of comparison <br/>
 </p>
<ul>
<li>OK - <b> <font color="#008000">green</font></b> </li>
<li>WARNING - <b> <font color="#B8860B">yellow</font></b> </li>
<li>FATAL or ERROR - <b> <font color="#FF0000">red</font></b> </li>
</ul>
<p><b>NOTE:</b> Currently highlighting is supported only for: </p>
<ul>
<li>standard performance metrics </li>
<li>monitoring metrics </li>
<li>custom metrics</li>
</ul>
<p><em> Validators </em> can be compared to limits and will influence decision, but are not highlighted <br/>
 <br/>
 To switch off highlighting - set following property to false: <br/>
 Web client: <br/>
  <div class="fragment"><div class="line">webui.enable.decisions.per.metric.highlighting=<span class="keyword">true</span></div>
</div><!-- fragment --></p>
<p>PDF report: <br/>
  <div class="fragment"><div class="line">report.enable.decisions.per.metric.highlighting=<span class="keyword">true</span></div>
</div><!-- fragment --> <br/>
</p>
<h1><a class="anchor" id="section_dm_setup_properties"></a>
Configure baseline and auxiliary parameters</h1>
<p>To provide comparison of your results to baseline values it is necessary to select baseline session Id <br/>
 Set following properties in you <em>environment.properties</em> file or via system properties:  <div class="fragment"><div class="line"><span class="preprocessor"># begin: following section is used for docu generation - Decision making by limits main</span></div>
<div class="line"><span class="preprocessor"></span></div>
<div class="line"><span class="preprocessor"># # # Baseline session Id # # #</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor"># Baseline session ID for session comparison.</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor"># By default this value is set to &#39;#IDENTITY&#39; =&gt; session will be compared with itself (for testing purposes). Comparison will always pass</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor"># If you would like to compare with some previous run, set this property equal to baseline session Id (f.e. 115)</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor"># Comparison will only work if test data is stored in DB</span></div>
<div class="line"><span class="preprocessor"></span></div>
<div class="line">chassis.engine.e1.reporting.session.comparison.baseline.session.id=#IDENTITY</div>
<div class="line"></div>
<div class="line"><span class="preprocessor"># end: following section is used for docu generation - Decision making by limits main</span></div>
</div><!-- fragment --></p>
<p>Optional: additional setting to define behavior in case of errors:  <div class="fragment"><div class="line"><span class="preprocessor"># begin: following section is used for docu generation - Decision making by limits aux</span></div>
<div class="line"><span class="preprocessor"></span></div>
<div class="line"><span class="preprocessor"># # # Decision when no matching metric for limit is found # # #</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor"># Valid when you are using decision making with limits</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor"># Describes: What decision should be taken when limit is specified, but no metric in the test matches metricName of this Limit</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor"># Default: OK - because this is not critical (you can specify limits in advance - it doen&#39;t influence quality of results)</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor"># Allowed values (Decision enum): OK, WARNING, ERROR, FATAL</span></div>
<div class="line"><span class="preprocessor"></span>chassis.decision.maker.with.limits.decisionWhenNoMetricForLimit=OK</div>
<div class="line"></div>
<div class="line"><span class="preprocessor"># # # Decision when no baseline value is found for metric # # #</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor"># Valid when you are using decision making with limits</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor"># Describes: What decision should be taken when baseline value can&#39;t be fetched for some metric (f.e. test or metric doesn&#39;t exist in baseline session)</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor"># Default: FATAL - because we can not compare results to baseline =&gt; we can not take decision</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor"># Allowed values (Decision enum): OK, WARNING, ERROR, FATAL</span></div>
<div class="line"><span class="preprocessor"></span>chassis.decision.maker.with.limits.decisionWhenNoBaselineForMetric=FATAL</div>
<div class="line"></div>
<div class="line"><span class="preprocessor"># # # Decision when several limits match single metric # # #</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor"># Valid when you are using decision making with limits</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor"># Describes: What decision should be taken when several limits match same metric (f.e. &#39;mon_cpu&#39; &amp; &#39;mon_cpu_user&#39; will match &#39;mon_cpu_user|agent_007 [127.0.1.1]|-avg&#39;)</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor"># Default: FATAL - because in this case we will have several decisions (equal to number of matching limits) =&gt; we can not decide what decision should be saved for this metric</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor"># Allowed values (Decision enum): OK, WARNING, ERROR, FATAL</span></div>
<div class="line"><span class="preprocessor"></span>chassis.decision.maker.with.limits.decisionWhenSeveralLimitsMatchSingleMetric=FATAL</div>
<div class="line"></div>
<div class="line"><span class="preprocessor"># end: following section is used for docu generation - Decision making by limits aux</span></div>
</div><!-- fragment --> <br/>
 </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Thu Jan 12 2017 12:27:34 for Jagger by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.4 </li>
  </ul>
</div>
</body>
</html>
